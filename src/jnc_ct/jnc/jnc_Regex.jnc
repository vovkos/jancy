//..............................................................................
//
//  This file is part of the Jancy toolkit.
//
//  Jancy is distributed under the MIT license.
//  For details see accompanying license.txt file,
//  the public copy of which is also available at:
//  http://tibbo.com/downloads/archive/jancy/license.txt
//
//..............................................................................

namespace jnc {

///+++

// . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

///; static char regexMatchTypeSrc [] =

/**
	\ingroup rtl
	\brief This struct holds the information about matched lexeme or sub-lexeme.
*/

struct RegexMatch
{
	//! Holds a pointer to the match (guaranteed to be null-terminated).

	char const* m_text;

	//! Holds offset of the match relative the beginning of input stream.

	size_t m_offset;

	//! Holds length of the match.

	size_t m_length;
}

// . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

///; static char regexStateTypeSrc [] =

/**
	\ingroup rtl
	\brief This class holds the lexeme buffer and the state of DFA constructed from an ``reswitch`` statement.

	Jancy ``reswitch`` statements allow for convenient creation of lexers/scanners.

	The idea is taken from well-known tools like *Lex*, *Flex*, *Ragel* etc.

	1. Define a list of recognized lexemes in the form of regular expressions.
	2. Specify which actions to execute when these lexemes are found in the input stream.
	3. Jancy compiler automatically builds a DFA to recognize your language and perform correspondig actions.

	To *execute* the resulting DFA you need a ``jnc.RegexState`` object -- it will hold the state of DFA and buffer matched lexemes. In its simplest form recognizer looks like this:

	.. ref-code-block::

		jnc.RegexState state;
		reswitch (state, p, length)
		{
		case "foo":
			// ...
			break;

		case r"bar\(d+)":
			print ($"bar id: $(state.m_subMatchArray [0].m_text)\n");
			break;

		case r"\s+":
			// ignore whitespace
			break;

		// ...
		}

	To employ incremental recognition, you would want to create some kind of a *match* function and call it each time the next chunk of data becomes available:

	.. ref-code-block::

		bool errorcode match (
			jnc.RegexState* state,
			const char* p,
			size_t length
			)
		{
			const char* end = p + length;

			// post-condition loop allows passing 'null' as eof
			do
			{
				reswitch (state, p, end - p)
				{
				case "foo":
					// ...
					break;

				case r"bar\(d+)":
					print ($"bar id: $(state.m_subMatchArray [0].m_text)\n");
					break;

				case r"\s+":
					// ignore whitespace
					break;

				// ...

				default:
					// we can get here for two reasons only:
					//   1) mismatch
					//   2) incremental recognition

					if (!state.m_consumedLength)
						return false;

					assert (state.m_isIncremental && state.m_consumedLength == end - p);
				}

				p += state.m_consumedLength; // advance to the next lexeme
			} while (p < end)

			return true;
		}

	Recognizer must be aware of the fact it is being fed the date chunk-by-chunk (and not as the whole). You do so by setting ``m_isIncremental`` field to ``true``:

	.. ref-code-block::

		jnc.RegexState state (true);  // turn on incremental matching

		// alternatively, assign:
		// state.m_isIncremental = true;

	Now, whenever the next portion of data becomes available, simply call:

	.. ref-code-block::

		size_t length = getNextPortionOfData (buffer);

		match (state, buffer, length);

	Pass zero-sized buffer to trigger ``eof`` processing:

	.. ref-code-block::

		match (state, null, 0);

*/

opaque class RegexState
{
	bool m_isIncremental;

	/**
		Holds the maximum buffer size for lexemes. Set before starting recognition.

		What happends when lexeme in the input stream does not fit inside the buffer, depends on the whether the captured part of lexeme *already* matches some rule. If yes, recognizer will execute corresponding action and then reset its state to initial value.

		If captured part of lexeme does not match any rules, ``write`` or ``recognize`` will return error.
	*/

	size_t autoget property m_matchLengthLimit;

	/**
		Holds the current offset of recognizer.

		Could be adjusted manually. For example, you can adjust ``m_currentOffset`` before starting recognition; when a lexeme is found, ``m_lexemeOffset`` will account for the initial offset (offset relative the beginning of the stream plus initial offset set before starting recognition).
	*/

	size_t autoget property m_currentOffset;

	/**
		Holds the actual length of data consumed during the last invokation of the DFA. When non-incremental recognizer discovers a match, ``m_consumedLength`` will always be the same as ``m_match.m_length``. In case of a incremental recognizer, ``m_consumedLength`` may be smaller than ``m_match.m_length`` (the match may be spread across multiple blocks of input data).
	*/

	size_t readonly m_consumedLength;

	/**
		\subgroup

		These fields hold information about the matched lexeme and, possibly, sub-lexemes (if capturing regular expressions groups were used).

		These fields should only be accessed from within **action** inside ``automaton`` function.
	*/

	RegexMatch readonly m_match;
	RegexMatch const* readonly m_subMatchArray;
	size_t readonly m_subMatchCount;

public:
	/**
		Constructor of ``jnc.Recognizer`` class. Accepts a single optional argument ``automatonFunc`` which, if supplied, will be written to ``m_automatonFunc`` and used for subsequent scanning.
	*/

	construct (bool isIncremental = false);

	/**
		Resets state of recognizer including all offsets and captured lexeme bytes.
	*/

	reset ();

protected:
	size_t exec (
		void thin* dfa,
		char const* p,
		size_t length
		);
}

//..............................................................................

///;

///---

} // namespace jnc
